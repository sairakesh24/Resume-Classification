{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f645121-0f40-483c-a382-7b2818e44d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 23:37:50.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:50.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.003 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.006 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.012 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.013 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.017 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.019 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.023 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.028 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.037 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-03 23:37:51.038 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import streamlit as st\n",
    "from docx import Document\n",
    "from io import BytesIO  # Import BytesIO to handle file streams\n",
    "import win32com.client  # For handling .doc files on Windows\n",
    "import tempfile  # To create temporary files for the uploaded .doc files\n",
    "import pythoncom  # For initializing COM\n",
    "\n",
    "# Load models\n",
    "word_vector = pickle.load(open(\"tfidf.pkl\", \"rb\"))\n",
    "model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)  \n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText\n",
    "\n",
    "category_mapping = {\n",
    "    1: \"Peoplesoft Resume\",\n",
    "    2: \"React Developer\",\n",
    "    3: \"SQL Developer\",\n",
    "    4: \"Workday\",\n",
    "}\n",
    "\n",
    "def extract_text_from_docx(uploaded_file):\n",
    "    # Use BytesIO to handle the uploaded file stream correctly\n",
    "    docx_file = BytesIO(uploaded_file.read())\n",
    "    doc = Document(docx_file)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def extract_text_from_doc(uploaded_file):\n",
    "    # Initialize COM\n",
    "    pythoncom.CoInitialize()\n",
    "    \n",
    "    # Save the uploaded .doc file to a temporary directory\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".doc\") as temp_file:\n",
    "        temp_file.write(uploaded_file.getbuffer())  # Save the uploaded file content\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    # Using win32com to extract text from .doc files on Windows\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(temp_file_path)  # Open the saved .doc file\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    \n",
    "    # Remove the temporary file after processing\n",
    "    os.remove(temp_file_path)\n",
    "    \n",
    "    # Uninitialize COM to clean up\n",
    "    pythoncom.CoUninitialize()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def categorize_resumes(uploaded_files, output_directory):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for uploaded_file in uploaded_files:\n",
    "        text = \"\"\n",
    "\n",
    "        if uploaded_file.name.endswith('.pdf'):  # Handle PDF files\n",
    "            reader = PdfReader(uploaded_file)\n",
    "            page = reader.pages[0]\n",
    "            text = page.extract_text()\n",
    "\n",
    "        elif uploaded_file.name.endswith('.docx'):  # Handle DOCX files\n",
    "            text = extract_text_from_docx(uploaded_file)\n",
    "        \n",
    "        elif uploaded_file.name.endswith('.doc'):  # Handle DOC files\n",
    "            text = extract_text_from_doc(uploaded_file)\n",
    "\n",
    "        # If the file is neither PDF, DOC, nor DOCX, skip processing\n",
    "        if not text:\n",
    "            st.warning(f\"Skipping {uploaded_file.name}. Unsupported file format.\")\n",
    "            continue\n",
    "\n",
    "        cleaned_resume = cleanResume(text)\n",
    "\n",
    "        input_features = word_vector.transform([cleaned_resume])\n",
    "        prediction_id = model.predict(input_features)[0]\n",
    "        category_name = category_mapping.get(prediction_id, \"Unknown\")\n",
    "        \n",
    "        category_folder = os.path.join(output_directory, category_name)\n",
    "        \n",
    "        if not os.path.exists(category_folder):\n",
    "            os.makedirs(category_folder)\n",
    "        \n",
    "        target_path = os.path.join(category_folder, uploaded_file.name)\n",
    "        with open(target_path, \"wb\") as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "        \n",
    "        results.append({'filename': uploaded_file.name, 'category': category_name})\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "st.title(\"Resume Categorizer Application\")\n",
    "st.subheader(\"With Python & Machine Learning\")\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose PDF, DOC, or DOCX files\", type=[\"pdf\", \"doc\", \"docx\"], accept_multiple_files=True)\n",
    "output_directory = st.text_input(\"Output Directory\", \"categorized_resumes\")\n",
    "\n",
    "if st.button(\"Categorize Resumes\"):\n",
    "    if uploaded_files and output_directory:\n",
    "        results_df = categorize_resumes(uploaded_files, output_directory)\n",
    "        st.write(results_df)\n",
    "        results_csv = results_df.to_csv(index=False).encode('utf-8')\n",
    "        st.download_button(\n",
    "            label=\"Download results as CSV\",\n",
    "            data=results_csv,\n",
    "            file_name='categorized_resumes.csv',\n",
    "            mime='text/csv',\n",
    "        )\n",
    "        st.success(\"Resumes categorization and processing completed.\")\n",
    "    else:\n",
    "        st.error(\"Please upload files and specify the output directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7966644-6ca5-48d0-8094-204275c6ad37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
